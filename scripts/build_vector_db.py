
import os
import sys
import re
import pickle
import threading
import google.generativeai as genai
from dotenv import load_dotenv
import numpy as np

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹ã‚ˆã†ã«ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# .envã®èª­ã¿è¾¼ã¿ï¼ˆè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹æƒ³å®šï¼‰
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env'))

GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
if not GEMINI_API_KEY:
    print("Error: GEMINI_API_KEY not found in environment variables.")
    sys.exit(1)

genai.configure(api_key=GEMINI_API_KEY)

TEXTBOOK_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data', 'textbook.txt')
OUTPUT_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data', 'textbook_vectors.pkl')

class TextbookManagerLogic:
    """app.pyã‹ã‚‰ãƒ­ã‚¸ãƒƒã‚¯ã ã‘æ‹å€Ÿï¼ˆä¾å­˜é–¢ä¿‚å›é¿ã®ãŸã‚å†å®šç¾©ï¼‰"""
    def __init__(self):
        self.sections = {} 
        self.toc = []
        self._load_textbook()

    def _load_textbook(self):
        if not os.path.exists(TEXTBOOK_PATH):
            print(f"Textbook file not found at: {TEXTBOOK_PATH}")
            return

        try:
            with open(TEXTBOOK_PATH, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.splitlines()
            current_header = "Introduction"
            current_content = []
            
            # app.py ã¨åŒã˜æ­£è¦è¡¨ç¾
            header_pattern = re.compile(r'^(ç¬¬[ï¼-ï¼™0-9]+[éƒ¨ç« ].*|[ï¼-ï¼™0-9]+ã€€.*|â—.*|ã€.*ã€‘.*)') 
            
            for line in lines:
                if header_pattern.match(line):
                    if current_content:
                        self.sections[current_header] = "\n".join(current_content)
                        self.toc.append(current_header)
                    current_header = line.strip()
                    current_content = [line]
                else:
                    current_content.append(line)
            
            if current_content:
                self.sections[current_header] = "\n".join(current_content)
                self.toc.append(current_header)
                
            print(f"âœ… Textbook loaded: {len(self.toc)} sections parsed.")
            
        except Exception as e:
            print(f"âŒ Failed to parse textbook: {e}")

def get_embedding(text):
    """Gemini APIã‚’ä½¿ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
    try:
        # embedding-001 ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        result = genai.embed_content(
            model="models/embedding-001",
            content=text,
            task_type="retrieval_document",
            title="Textbook Section"
        )
        return result['embedding']
    except Exception as e:
        print(f"âš ï¸ Embedding failed: {e}")
        return None

def build_vector_db():
    print("ğŸš€ Starting Vector DB Build...")
    
    tm = TextbookManagerLogic()
    if not tm.sections:
        print("âŒ No sections found. Exiting.")
        return

    vector_db = [] # List of {'title': title, 'content': content, 'vector': vector}
    
    total = len(tm.toc)
    print(f"Processing {total} sections...")
    
    for i, title in enumerate(tm.toc):
        content = tm.sections[title]
        # å†…å®¹ãŒçŸ­ã™ãã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹æ¤œè¨ï¼ˆä»Šå›ã¯ã™ã¹ã¦å«ã‚ã‚‹ï¼‰
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã‚‚å«ã‚ã‚‹ã¨æ¤œç´¢ç²¾åº¦ãŒä¸ŠãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
        text_to_embed = f"{title}\n{content}"
        
        vector = get_embedding(text_to_embed)
        
        if vector:
            vector_db.append({
                'title': title,
                'content': content,
                'vector': vector
            })
            print(f"[{i+1}/{total}] Embed success: {title}")
        else:
            print(f"[{i+1}/{total}] Embed FAILED: {title}")
            
        # APIåˆ¶é™è€ƒæ…®ï¼ˆå¿…è¦ãªã‚‰ï¼‰
        # time.sleep(0.1) 

    print(f"âœ¨ Build complete. Saving {len(vector_db)} items to {OUTPUT_PATH}...")
    
    with open(OUTPUT_PATH, 'wb') as f:
        pickle.dump(vector_db, f)
        
    print("âœ… Done!")

if __name__ == "__main__":
    build_vector_db()
